<!DOCTYPE html><html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternative" href="/atom.xml" title="Programio" type="application/atom+xml"><link rel="icon" href="/images/favicon.png"><title>Samza: distributed stream processing framework - Programio</title><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro"><link rel="stylesheet" href="/css/main.css" type="text/css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--></head><body><header class="head"><h1 class="head-title u-fl"> <a href="/">Programio</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a href="/" class="head-nav__link">Domů</a></li><li class="head-nav__item"><a href="/archives" class="head-nav__link">Archiv</a></li><li class="head-nav__item"><a href="http://www.havrlant.cz/" class="head-nav__link">O autorovi</a></li><li class="head-nav__item"><a href="/rss.xml" class="head-nav__link">RSS</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time datetime="2015-04-06T14:15:34.000Z" class="post__time">6. 4. 2015</time><h1 class="post__title"><a href="/samza/">Samza: distributed stream processing framework</a></h1></header><div class="post__main echo"><p>V předchozích částech jsme se bavili o <a href="/kafka">Kafce</a>, což je aplikace, která slouží k přenosu zpráv z jednoho serveru na jiný. <a href="http://samza.apache.org/" target="_blank" rel="external">Samza</a> je Javový framework, který nám pomáhá tyto protékající zprávy dále zpracovávat.</p>
<h2 id="co-děláme-se-zprávami-před-uložením-do-databáze">Co děláme se zprávami před uložením do databáze</h2>
<p>Jaké zpracování mám na mysli? Vraťme se k úkolu, který jsem popisoval v předchozích částech. Provozujeme burzu s reklamními pozicemi. Pro každou reklamní pozici pošleme několika serverům, DSPéčkům, nabídku (bid request) a očekáváme odpověď (bid response). Tato data ukládáme do Kafka topicu. (<a href="/kafka/">detailněji jsem to popsal minule</a>) Co s těmi daty dále děláme?</p>
<ul>
<li><p>Požadavky a odpovědi jsou <a href="https://code.google.com/p/openrtb/wiki/OpenRTB_Examples" target="_blank" rel="external">vcelku nehezké JSONy</a>. My na ukládání používáme Druid.io, která nepodporuje ukládání takto složitých JSONů, takže potřebujeme něco, co nám zanořený JSON “zlinearizuje” na jeden klasický řádek o x sloupcích.</p></li>
<li><p><em>bidrequests</em> a <em>bidresponses</em> jsou dva nezávislé topicy, v jednom jsou požadavky a v druhém odpovědi. Do databáze ale chceme ukládat jeden záznam, který bude uchovávat jak data z požadavku, tak data z odpovědi, tj. chceme ukládat něco jako <code>merge(request, response)</code>. Každý požadavek jde s každou odpovědí spárovat podle <em>requestID</em>. Potřebujeme nějaký program, který bude číst současně oba topicy a pro každou odpověď nalezne původní požadavek na základě <em>requestID</em>, tyto JSONy nějak inteligentně spojí a pošle zase dál na zpracování.</p></li>
<li><p>V jiné části systému do Kafky ukládáme informace o tom, když někdo klikne na banner. Pokud na něj někdo klikne dvakrát rychle za sebou, vyšlou se na naše servery dva požadavky o kliku, které budou úplně stejné. V Kafka topicu budou dvě shodné zprávy, které ale nechceme ukládat do databáze. Potřebujeme program, který z topicu vyháže duplikace.</p></li>
<li><p>Když někdo klikne na reklamu, máme přímo v GET požadavku informaci o tom, na jakou reklamu klikl. Nemáme ale například informaci o tom, jakému klientovi tato reklama patří. Přitom je to informace, kterou bychom rádi měli uloženou přímo se zprávou o kliku. Musíme tak mít nějaký program, který se ještě před uložením zeptá nějaké databáze, který klient vlastní reklamu s tímto ID a tuto informaci musí přidat do zprávy.</p></li>
</ul>
<p>Toto jsou asi čtyři nejčastější případy využití nějaké (pre)processing aplikace: transformace dat, join dat, filtrace dat a obohacení dat. Samza nám s tímto preprocessingem velmi pomáhá.</p>
<h2 id="proč-vůbec-používat-nějaký-framework">Proč vůbec používat nějaký framework?</h2>
<p>Všechny zprávy nám tečou v Kafce. Co nám brání napsat si Javovou (Python, Ruby, Node.JS, …) aplikaci, která bude číst zprávy z Kafky, něco s nimi udělá a pak je zase uloží zpět do Kafky nebo jinam? Samozřejmě, že to jde, ale museli bychom řešit problémy, které už jsou v Samze vyřešené. Například:</p>
<ul>
<li><p>Co se stane, když z nějakého důvodu naše aplikace spadne? Samza se automaticky postará o znovunastartování aplikace.</p></li>
<li><p>Jak moc škálovatelná naše aplikace bude? V Samze stačí přepsat jedno číslo v configu a rázem neběží na jednom serveru, ale na deseti.</p></li>
<li><p>Často je potřeba <em>windowing</em>, který využíváme u párování požadavků a odpovědí. Obecně jde o to, jak provést nějakou akci každých deset sekund nebo jak přidat našim datům nějaké TTL – třeba když přečteme z topicu nějaký bid request, tak na odpovídající bid response čekáme jen určitou dobu. Dalším příkladem může být plovoucí průměr nějakých dat za posledních x sekund atp.</p>
<p>Samza nám pomáhá tím, že má vlastní <a href="http://samza.apache.org/learn/documentation/0.8/container/event-loop.html" target="_blank" rel="external">event loop</a> a poskytuje nám dvě základní metody: <code>process</code> a <code>window</code>. Metoda <code>process</code> se zavolá, když přijde nová zpráva, metoda <code>window</code> se zavolá každých x sekund (konfigurovatelné). Výhodou je, že obě metody se vykonávají ve stejném vlákně (podobně jako v Node.JS), takže nehrozí žádné kolize kvůli více vláknům a podobně. Přitom toto primitivum nám stačí na implementaci všech předchozích scénářů.</p></li>
<li><p>Vezměme si příklad s filtrováním duplikovaných zpráv. Abychom byli schopni odstraňovat duplikované zprávy, musíme si nutně <em>někde</em> pamatovat ty zprávy, které už jsme zpracovali (nebo alespoň nějaká IDéčka, případně jejich hashe apod.). Když si tyto zprávy budeme ukládat do paměti, přijdeme o ně ve chvíli, kdy náš program spadne. Když si zprávy budeme ukládat do nějaké vzdálené databáze, bude to nejspíš pomalé. Samza to řeší tak, že si data lze uložit lokálně do key-value databáze, ta může být i in-memory, a každá změna v databázi je zálohována mimo server, na kterém běží Samza. Při restartu Samzy lze všechna data uložená do key-value databáze zpětně získat.</p></li>
</ul>
<p>Toto všechno jsou problémy, na které bychom rychle narazili, kdybychom takový <em>preprocessing</em> zpráv psali sami od píky. Samza je řeší za nás, proto ji používáme. Samza dělá <a href="http://samza.apache.org/learn/documentation/0.7.0/comparisons/spark-streaming.html" target="_blank" rel="external">něco podobného jako Apache Spark</a>, pokud znáte.</p>
<h2 id="jak-samza-funguje">Jak Samza funguje</h2>
<p>Samza je framework napsaný v Javě, který se spouští nad Hadoopem; využívá YARN. K čemu je to dobré? Hadoop cluster je hodně stručně řečeno hromada počítačů, na kterých běží Hadoop aplikace, která monitoruje, jaké procesy na daném stroji běží a kolik prostředků zabírají, případně kolik prostředků si procesy alokovaly. Součástí Hadoopu je i HDFS, distribuovaný file system, ale ten Samza téměř nevyužívá.</p>
<p>Pokud chceme v Hadoopu spustit nějakou novou aplikaci, řekneme to YARNu, což je část Hadoopu. Zároveň s tím řekneme, kolik prostředků budeme pro tu aplikaci potřebovat (2 GB RAM, 1 CPU, například). YARN se podívá, jestli je na nějakém počítači tolik volných prostředků a pokud ano, spustí tam danou aplikaci. My jako uživatelé komunikujeme pouze s YARNem a nestaráme se o to, na kterém počítači se nakonec naše aplikace spustí. YARN zároveň hlídá, jestli naše aplikace běží – pokud spadne, automaticky ji spustí znova.</p>
<p>Pro nás je důležité, že se nemusíme starat o distribuci naší Samza aplikace nebo nemusíme ručně zajišťovat, aby naše aplikace znova naběhla, pokud by náhodou spadla. Pokud navíc máte přehled o Hadoop ekosystému, můžete využít nějaké další programy na správu Samza aplikací.</p>
<p>Samza aplikace se může spustit na kterémkoliv počítači v Hadoop clusteru, což má i nepříjemné důsledky. Třeba nemá smysl dlouhodobě ukládat data na lokální disk – po pádu aplikace může YARN aplikaci spustit na úplně jiném počítači a Samza k těm souborům najednou nebude mít přístup.</p>
<h2 id="hello-world-v-samze">Hello World v Samze</h2>
<p>Samza je out-of-the-box propojena s Kafkou. To není úplně náhoda, protože Samzu vyvíjí LinkedIn, stejně jako Kafku. Nicméně existuje možnost, jak Samzu propojit i s jnými systémy. My ale využíváme Kafku, takže v dalších částech budu popisovat právě propojení s Kafkou.</p>
<p>V nastavení Samzy nejdříve určíme, jaké Kafka topicy chceme číst. My chceme číst dva topicy, takže to zapíšeme takto:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">task.inputs=kafka.bidresponses,kafka.bidrequests</span><br></pre></td></tr></table></figure>
<p>V kódu implementujeme rozhraní <a href="http://samza.apache.org/learn/documentation/0.7.0/api/javadocs/org/apache/samza/task/StreamTask.html" target="_blank" rel="external">StreamTask</a>, která má metodu <code>process</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@Override&#10;public void process(IncomingMessageEnvelope envelope, MessageCollector collector, TaskCoordinator coordinator) throws Exception &#123;&#10;    System.out.println(envelope.getMessage());&#10;&#125;&#10;``` &#10;&#10;Poka&#382;d&#233;, kdy&#382; Samza p&#345;e&#269;te z topicu n&#283;jakou zpr&#225;vu, zavol&#225; metodu `process` a zpr&#225;vu ulo&#382;&#237; do argumentu `envelope` spolu s dal&#353;&#237;mi metadaty. Uk&#225;zka ned&#283;l&#225; nic jin&#233;ho, ne&#382; &#382;e danou zpr&#225;vu vyp&#237;&#353;e na standardn&#237; v&#253;stup. V nastaven&#237; si m&#367;&#382;eme zvolit, jak&#253; (de)serializ&#233;r bude pro zpr&#225;vy pou&#382;it:</span><br></pre></td></tr></table></figure>
<p>systems.kafka.samza.msg.serde=string <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#10;Toto nastaven&#237; znamen&#225;, &#382;e ka&#382;d&#225; zpr&#225;va, kter&#225; samoz&#345;ejm&#283; p&#345;ijde jen jako pole bajt&#367;, bude serializov&#225;na na Javov&#253; String. M&#367;&#382;ete si napsat vlastn&#237; (de)serializ&#233;r. &#10;&#10;Tohle jsou asi nejd&#367;le&#382;it&#283;j&#353;&#237; nastaven&#237; a nejd&#367;le&#382;it&#283;j&#353;&#237; funkce, kter&#233; v Samze jsou. Pokud si chcete Samzu opravdu vyzkou&#353;et, projd&#283;te si [Hello Samza](http://samza.apache.org/startup/hello-samza/0.8/). &#10;&#10;&#10;## Propojen&#237; s Kafkou&#10;&#10;Z&#225;kladn&#237;m stavebn&#237;m prvkem Samzy je n&#283;jak&#253; *StreamTask*, tedy t&#345;&#237;da, kter&#225; m&#225; metodu `process` a kter&#225; se star&#225; o zpracov&#225;v&#225;n&#237; zpr&#225;v, kter&#233; te&#269;ou do Samzy. Samza framework vytv&#225;&#345;&#237; instanci n&#283;jak&#233;ho StreamTasku na za&#269;&#225;tku b&#283;hu programu a tato instance p&#345;e&#382;&#237;v&#225; a&#382; do konce aplikace. &#10;&#10;Samza d&#225;le vytv&#225;&#345;&#237; instanci StreamTasku pro ka&#382;dou partition v Kafka topicu. M&#225;-li n&#225;&#353; topic 8 partition&#367;, vytvo&#345;&#237; se 8 instanc&#237; na&#353;eho konkr&#233;tn&#237;ho StreamTasku. Ka&#382;d&#253; StreamTask pak &#269;te svou vlastn&#237; partition. V&#353;echny instance pob&#283;&#382;&#237; v jednom vl&#225;kn&#283;, nemus&#237;me se tak b&#225;t n&#283;jak&#253;ch synchroniza&#269;n&#237;ch probl&#233;m&#367;. &#10;&#10;### YARN kontejnery&#10;&#10;Co ale d&#283;lat, kdy&#382; n&#225;&#353; Samza job nest&#237;h&#225; zpracov&#225;vat zpr&#225;vy, kter&#233; do Kafky pos&#237;l&#225;me? Proto&#382;e v&#353;echny instance StreamTasku b&#283;&#382;&#237; by design v jednom vl&#225;kn&#283;, nesta&#269;&#237; n&#225;m p&#345;idat CPU nebo n&#283;co podobn&#233;ho. Mus&#237;me zm&#283;nit po&#269;et kontejner&#367;, ve kter&#253;ch se Samza job spou&#353;t&#237;:</span><br></pre></td></tr></table></figure></p>
<p>yarn.container.count=4 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#10;Kontejner je pojem z YARNu/Hadoopu, pro n&#225;s aktu&#225;ln&#283; sta&#269;&#237;, kdy&#382; si p&#345;edstav&#237;me, &#382;e jeden kontejner = jeden Java proces = 1 vyu&#382;it&#233; CPU. V uk&#225;zce jsme nastavili &#269;ty&#345;i kontejnery, co&#382; znamen&#225;, &#382;e kdy&#382; spust&#237;me Samza job, vytvo&#345;&#237; se celkem &#269;ty&#345;i kontejnery / &#269;ty&#345;i Java procesy, p&#345;i&#269;em&#382; ka&#382;d&#253; m&#367;&#382;e zabrat a&#382; jedno cel&#233; CPU. V ka&#382;d&#233;m kontejneru se budou &#269;&#237;st pr&#225;v&#283; dv&#283; Kafka partitiony. Nem&#225; smysl nastavovat v&#237;ce ne&#382; osm kontejner&#367;, proto&#382;e jedna Kafka partition nem&#367;&#382;e b&#253;t &#269;tena ve dvou kontejnerech. &#10;&#10;To ale vyvol&#225;v&#225; jeden probl&#233;m: v jedn&#233; partition Kafky by m&#283;lo t&#233;ct maxim&#225;ln&#283; tolik zpr&#225;v, kolik jsme schopni zpracov&#225;vat na jednom CPU v Samze. Proto&#382;e pokud by v jedn&#233; partition teklo v&#237;ce zpr&#225;v, nebudeme nikdy schopni v Samze zpracov&#225;vat aktu&#225;ln&#237; data, budeme se neust&#225;le zpo&#382;&#271;ovat. Pokud nest&#237;h&#225;me zpracov&#225;vat topic *bidrequests*, m&#225;me n&#225;sleduj&#237;c&#237; mo&#382;nosti: &#10;&#10;- Napsat jin&#253;, jednodu&#353;&#353;&#237;, Samza job, kter&#253; bude &#269;&#237;st zpr&#225;vy z jedn&#233; partiton topicu *bidrequests* a bude je ukl&#225;dat do jin&#233;ho topicu, nap&#345;&#237;klad *bidrequests_splitted*, kter&#233;mu zv&#283;t&#353;&#237;me po&#269;et partiton. Budeme &#269;&#237;st zpr&#225;vy z partiton 0 topicu *bidrequests* a budeme je pos&#237;lat do partiton 0, 1, 2, 3 topic *bidrequests_splitted*. Zpr&#225;vy z partiton 1 budeme pos&#237;lat do 4, 5, 6, 7 atp. T&#237;m doc&#237;l&#237;me toho, &#382;e v jedn&#233; partiton topicu *bidrequests_splitted* bude &#269;tvrtina zpr&#225;v oproti jedn&#233; partiton topicu *bidrequests*. Pokud je v jedn&#233; partition tolik zpr&#225;v, &#382;e ani tato mo&#382;nost nep&#345;ipad&#225; v &#250;vahu, zb&#253;v&#225; prakticky jen n&#225;sleduj&#237;c&#237; mo&#382;nost: &#10;&#10;- Zv&#253;&#353;it po&#269;et partiton topicu *bidrequests* a upravit producery. &#10;&#10;Tak&#382;e ve stru&#269;nosti: volba `yarn.container.count` v&#237;ce m&#233;n&#283; nastavuje po&#269;et CPU, kter&#233; m&#367;&#382;e job se&#382;rat a toto &#269;&#237;slo nem&#367;&#382;e b&#253;t nikdy vy&#353;&#353;&#237; ne&#382; po&#269;et partiton vstupn&#237;ho Kafka kan&#225;lu. &#10;&#10;&#10;### V&#237;ce vstupn&#237;ch Kafka topic&#367;&#10;&#10;Jak se budou StreamTasky chovat, kdy&#382; m&#225;me na vstupu v&#237;ce Kafka topic&#367;? Jednodu&#353;e tak, &#382;e se vytvo&#345;&#237; tolik instanc&#237; StreamTask&#367;, jak&#253; je maxim&#225;ln&#237; po&#269;et partition&#367; ze v&#353;ech topic&#367;. &#268;teme-li &#269;ty&#345;i topicy, kter&#233; maj&#237; po&#269;et partition&#367; rovny 2, 5, 7, 6, tak se vytvo&#345;&#237; celkem 7 instanc&#237; StreamTask&#367;. Tohle moc smyslupln&#233; nen&#237;, obvykl&#233; je, &#382;e po&#269;et partition&#367; v&#353;ech topic&#367; je identick&#253;. &#10;&#10;Na&#353;e topicy *bidrequests* a *bidresponses* maj&#237; zat&#237;m 32 partition&#367; a spou&#353;t&#237;me je v osmi kontejnerech; ka&#382;d&#253; kontejner &#269;te &#269;ty&#345;i partitiony. Celkem se vytvo&#345;&#237; 32 instanc&#237; StreamTask&#367;. Ka&#382;d&#253; StreamTask &#269;te v&#382;dy stejnou partition nap&#345;&#237;&#269; v&#353;emi topicy. Nult&#253; StreamTask &#269;te data z partition 0 topicu *bidrequests* a z partition 0 topicu *bidresponses*. T&#345;et&#237; StreamTask &#269;te t&#345;et&#237; partition *bidrequests* i t&#345;et&#237; partition *bidresponses* atp. &#10;&#10;Jedn&#237;m z &#250;kol&#367;, kter&#233; n&#225;&#353; Samza job d&#283;l&#225; je, &#382;e p&#225;ruje po&#382;adavky a odpov&#283;di. V&#353;echny po&#382;adavky a odpov&#283;di, kter&#233; se t&#253;kaj&#237; jedn&#233; konkr&#233;tn&#237; imprese maj&#237; shodn&#233; *requestId*. Mus&#237;me b&#253;t schopni zajistit, aby po&#382;adavek s *requestId* 4742 &#353;el do stejn&#233; partition jako odpov&#283;&#271; s *requestId* 4742. Jinak je nikdy nesp&#225;rujeme, proto&#382;e pokud bude po&#382;adavek v partition 2 a odpov&#283;&#271; v partition 7, m&#367;&#382;ou je p&#345;e&#269;&#237;st dva r&#367;zn&#233; Samza joby, kter&#233; potenci&#225;ln&#283; ani neb&#283;&#382;&#237; na stejn&#233; ma&#353;in&#283; -- a i kdyby b&#283;&#382;ely, tak by se je p&#345;e&#269;etly dv&#283; r&#367;zn&#233; instance StreamTasku. &#10;&#10;Toho jsme doc&#237;lili tak, &#382;e &#269;&#237;slo partition, do kter&#233; se maj&#237; po&#382;adavky a odpov&#283;di pos&#237;lat, jsme vypo&#269;&#237;tali na z&#225;klad&#283; *requestId*, tj. asi takto:</span><br></pre></td></tr></table></figure></p>
<p>function getPartitionNumber(message, numberOfPartitions) { return murmurhash(message.requestId) % numberOfPartitions; } ```</p>
<p>Napsal jsem, že kód Samza jobu běží v jednom vlákně, takže by se zdálo, že nikdy nemůže zabírat více než jedno CPU. V realitě ale pozorujeme, že náš Samza job zabírá třeba 130 % CPU. Přičítáme to tomu, že náš kód sice v jednom vlákně běží, ale kromě našeho kódu je tam ještě kód frameworku, který už nejspíš běží v jiných vláknech. V těch pak probíhá čtení zpráv z Kafky nebo zápis do Kafky, takže v součtu může jeden Samza job zabrat více než 1 CPU.</p>
<h2 id="příště">Příště…</h2>
<p>Příště se podíváme na to, co je to ten windowing, jak lze využít metodu <code>window</code> a jaké jsou s tím spojeny problémy.</p>
<div class="relatedBox"><div class="relatedArticlesBox"><h2 id="relatedArticles">Související články:</h2><ol><li><a href="/lambda-architecture/">Jak zpracováváme velké množství dat: Lambda Architecture</a></li><li><a href="/kafka/">Kafka messaging system</a></li><li><a href="/kafka-consumer/">Jak funguje Kafka consumer</a></li><li><a href="/kafka-replikace/">Jak funguje replikace v Kafce</a></li><li><a href="/samza-windowing/">Windowing v Samze</a></li><li><a href="/samza-local-state/">Uložení lokálního stavu v Samze</a></li><li><a href="/druid-io/">Druid.io: distribuovaná immutable databáze pro analytické výpočty</a></li><li><a href="/druid-io-architektura/">Architektura Druid.io</a></li><li><a href="/druid-io-ingest/">Jak Druid.io agreguje data</a></li></ol></div></div><div class="articleTags"><strong><a href="/tags/bigdata">#bigdata</a></strong>, <strong><a href="/tags/samza">#samza</a></strong></div></div></article><div style="text-align: right"><div class="fb-like" data-layout="button_count" data-action="like" data-show-faces="true" data-share="true" style="margin-top: 10px; height: 30px"></div></div><div class="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/bigdata/" class="post__tag__link">bigdata</a></li><li class="post__tag__item"><a href="/tags/samza/" class="post__tag__link">samza</a></li></ul><a href="/samza/#disqus_thread" class="post__foot-link u-fr">Komentáře</a></footer></main><footer class="foot"><div class="foot-copy u-fl"><a href="/">Programio</a> píše <a href="http://www.havrlant.cz/">Lukáš Havrlant</a></div><menu class="page-menu u-fr"><li class="page-menu__item"><a title="Previous" href="/samza-windowing/" class="page-menu__link icon-arrow-left"></a></li><li class="page-menu__item"><a title="Next" href="/kafka-replikace/" class="page-menu__link icon-arrow-right"></a></li></menu></footer><script>(function(h,g,l,k,j,i){j=h.createElement(g),i=h.getElementsByTagName(g)[0],
j.src="//"+l+".disqus.com/"+k+".js",i.parentNode.insertBefore(j,i)})
(document,"script","programio","embed");
</script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
e=o.createElement(i);r=o.getElementsByTagName(i)[0];
e.src='//www.google-analytics.com/analytics.js';
r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
ga('create','UA-1559810-13');ga('send','pageview');
</script><div id="fb-root"></div><script>(function(d, s, id) {
var js, fjs = d.getElementsByTagName(s)[0];
if (d.getElementById(id)) return;
js = d.createElement(s); js.id = id;
js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&appId=166268190106534&version=v2.0";
fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script></body></html>